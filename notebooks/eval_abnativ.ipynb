{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… utils ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ. íƒìƒ‰ ê²½ë¡œ: /mnt/c4a1c56d-0589-48cd-9717-f6c33a86fa3b/Tools/ImmunoSeq/src\n",
      "--- K-mer í’€ ë¡œë”© ì‹œì‘ ---\n",
      "âœ… K-mer í’€ ë¡œë“œ ì™„ë£Œ.\n",
      "\n",
      "--- ë°ì´í„°ì…‹ 'vkappa' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- ìƒìˆ˜ ì •ì˜ ë° ê²½ë¡œ ì„¤ì • ---\n",
    "DATA_DIR = '../data' \n",
    "UTILS_DIR = '../src' \n",
    "MIN_MER, MAX_MER = 8, 13\n",
    "\n",
    "# --- ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸ ê²½ë¡œ ì„¤ì • ---\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), UTILS_DIR))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "try:\n",
    "    from utils import get_kmers, check_response, emit_metrics\n",
    "    print(f\"âœ… utils ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ. íƒìƒ‰ ê²½ë¡œ: {utils_path}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: utils ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ íŒŒì¼ ì´ë¦„ ì •ì˜\n",
    "TEST_DATASETS = {\n",
    "        \"vh\": \n",
    "            {\n",
    "            \"human\": \"test_human_VH_shuf_no_dupli_aligned_10k.txt\", \"diverse\": \"diverse_5_human_VH_biophi_and_test_seqs.txt\",       \n",
    "            \"mouse\": \"mouse_VH_cleaned_aligned_10k.txt\", \"rhesus\": \"rhesus_VH_cleaned_aligned_10k.txt\",      \n",
    "            \"pssm\": \"rd_pssm_human_VH_random_10k.txt\",\n",
    "            },\n",
    "        \"vkappa\":  \n",
    "            {\n",
    "            \"human\": \"test_human_VKappa_shuf_no_dupli_aligned_10k.txt\", \"diverse\": \"diverse_2_5_human_VKappa_biophi_and_test_seqs.txt\", \n",
    "            \"mouse\": \"mouse_VKappa_cleaned_aligned_10k.txt\", \"rhesus\": \"rhesus_VKappa_cleaned_aligned_10k.txt\",  \n",
    "            \"pssm\": \"rd_pssm_human_VKappa_random_10k.txt\",\n",
    "            },\n",
    "        \"vlambda\": \n",
    "            {\n",
    "            \"human\": \"test_human_VLambda_shuf_no_dupli_aligned_10k.txt\", \"diverse\": \"diverse_2_5_VLambda_biophi_and_test_seqs.txt\",      \n",
    "            \"mouse\": \"mouse_VLambda_cleaned_aligned_all.txt\", \"rhesus\": \"rhesus_VLambda_cleaned_aligned_10k.txt\", \n",
    "            \"pssm\": \"rd_pssm_human_VLambda_random_10k.txt\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "# --- í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ë³€ê²½ ì—†ìŒ) ---\n",
    "\n",
    "def read_txt(fname: str) -> list:\n",
    "    \"\"\"ì§€ì •ëœ ê²½ë¡œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì‹œí€€ìŠ¤ë¥¼ ì½ì–´ì™€ '-' ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.\"\"\"\n",
    "    seqs = []\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                seqs.append(line.strip().replace('-', ''))\n",
    "        return seqs\n",
    "    else:\n",
    "        print(f\"âš ï¸ ê²½ê³ : íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {fname}\")\n",
    "        return []\n",
    "\n",
    "def load_kmer_pools(data_dir: str, min_mer: int, max_mer: int) -> tuple:\n",
    "    \"\"\"ì§€ì •ëœ K-mer ë²”ìœ„ì— ëŒ€í•´ Pickle íŒŒì¼ì—ì„œ K-mer í’€ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    pools_human, pools_paired_human, pools_paired_mouse = {}, {}, {}\n",
    "    for mer in range(min_mer, max_mer):\n",
    "        try:\n",
    "            pkl_human = os.path.join(data_dir, f'human_{mer}mer.dump')\n",
    "            with open(pkl_human, 'rb') as f: pools_human[mer] = pickle.load(f)\n",
    "            pkl_paired_human = os.path.join(data_dir, f'oas_paired_human_{mer}mer.dump')\n",
    "            with open(pkl_paired_human, 'rb') as f: pools_paired_human[mer] = pickle.load(f)\n",
    "            pkl_paired_mouse = os.path.join(data_dir, f'oas_paired_mouse_{mer}mer.dump')\n",
    "            with open(pkl_paired_mouse, 'rb') as f: pools_paired_mouse[mer] = pickle.load(f)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"âŒ K-mer í’€ ë¡œë“œ ì˜¤ë¥˜ (mer={mer}): íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {e}\")\n",
    "            raise \n",
    "    return pools_human, pools_paired_human, pools_paired_mouse\n",
    "\n",
    "def calc_scores(sequences: list, pool_pos: list, pool_neg: list, label: int) -> tuple:\n",
    "    \"\"\"ì£¼ì–´ì§„ ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ K-mer í’€ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\"\"\"\n",
    "    pred, true = [], []\n",
    "    if not sequences: return pred, true\n",
    "    assert len(sequences) > 0\n",
    "\n",
    "    for sequence in sequences:\n",
    "        scores, total_response, total_kmers_count = {}, 0, 0\n",
    "        for mer in range(MIN_MER, MAX_MER):\n",
    "            kmers = get_kmers(sequence, mer, mer)\n",
    "            pool_mer_pos = [item[mer] for item in pool_pos if mer in item]\n",
    "            pool_mer_neg = [item[mer] for item in pool_neg if mer in item]\n",
    "            subscores, subresponse = check_response(kmers, mer, pool_mer_pos, pool_mer_neg, scores)\n",
    "            total_response += subresponse\n",
    "            total_kmers_count += len(kmers)\n",
    "            scores = subscores\n",
    "        final_score = total_response / max(1, total_kmers_count)\n",
    "        pred.append(final_score)\n",
    "        true.append(label)\n",
    "    return pred, true\n",
    "\n",
    "# --- classification í•¨ìˆ˜: íŒŒì¼ ì €ì¥ ë¡œì§ ì œê±° ë° ì¸ë¼ì¸ ì¶œë ¥ìœ¼ë¡œ ìˆ˜ì • ---\n",
    "\n",
    "def classification(pred: list, label: list, task_name: str, dataset_type: str):\n",
    "    \"\"\"\n",
    "    ì˜ˆì¸¡ ì ìˆ˜ì™€ ì°¸ ë ˆì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ROC ê³¡ì„  ë° ì„ê³„ê°’ë³„ ì„±ëŠ¥(MCC, F1)ì„ í”Œë¡œíŒ…í•˜ê³  \n",
    "    Jupyter Notebookì— ë°”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ê³µí†µ ì§€í‘œ ê³„ì‚°\n",
    "    auroc = roc_auc_score(label, pred)\n",
    "    auprc = average_precision_score(label, pred)\n",
    "\n",
    "    # 2. ROC Curve ë°ì´í„° ìƒì„± ë° í”Œë¡¯\n",
    "    fpr, tpr, _ = roc_curve(label, pred)\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUROC = {auroc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curve: {dataset_type} - {task_name}', fontsize=14)\n",
    "    plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig() í˜¸ì¶œì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    plt.close() # ë‹¤ìŒ ì…€ ì‹¤í–‰ì„ ìœ„í•´ figureë¥¼ ë‹«ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    # 3. MCCì™€ F1-Score vs. Threshold ë°ì´í„° ìƒì„± ë° í”Œë¡¯\n",
    "    intervals = np.arange(0, 1, 0.01) \n",
    "    mccs, f1s = [], []\n",
    "    \n",
    "    for interval in intervals:\n",
    "        fpred = [1 if i >= interval else 0 for i in pred]\n",
    "        metric = emit_metrics(fpred, label) \n",
    "        mccs.append(metric[2]) # MCC\n",
    "        f1s.append(metric[1])  # F1-Score\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(intervals, mccs, label='MCC', color='blue', lw=2)\n",
    "    plt.plot(intervals, f1s, label='F1-Score', color='green', lw=2, linestyle='--')\n",
    "    \n",
    "    best_mcc_index = np.argmax(mccs)\n",
    "    best_mcc = mccs[best_mcc_index]\n",
    "    best_threshold = intervals[best_mcc_index]\n",
    "    \n",
    "    plt.scatter(best_threshold, best_mcc, color='red', marker='o', s=50, zorder=5,\n",
    "                label=f'Optimal MCC: {best_mcc:.4f} @ Thr {best_threshold:.2f}')\n",
    "    \n",
    "    plt.xlabel('Threshold', fontsize=12)\n",
    "    plt.ylabel('Metric Score', fontsize=12)\n",
    "    plt.title(f'Performance vs. Threshold: {dataset_type} - {task_name}', fontsize=14)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower left', fontsize=10)\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig() í˜¸ì¶œì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    plt.close() # ë‹¤ìŒ ì…€ ì‹¤í–‰ì„ ìœ„í•´ figureë¥¼ ë‹«ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    print(f\"âœ… {task_name} ë¶„ì„ ê²°ê³¼: AUROC={auroc:.4f}, AUPRC={auprc:.4f}, Max MCC={best_mcc:.4f} (ê·¸ë˜í”„ ì¶œë ¥ ì™„ë£Œ)\")\n",
    "\n",
    "\n",
    "def run_benchmark(dataset_type: str, data_dir: str):\n",
    "    \"\"\"K-mer í’€ì„ ë¡œë“œí•˜ê³  ì§€ì •ëœ ë°ì´í„°ì…‹ì— ëŒ€í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    print(\"--- K-mer í’€ ë¡œë”© ì‹œì‘ ---\")\n",
    "    pools_human, pools_paired_human, pools_paired_mouse = load_kmer_pools(\n",
    "        data_dir=data_dir, \n",
    "        min_mer=MIN_MER, \n",
    "        max_mer=MAX_MER\n",
    "    )\n",
    "    print(\"âœ… K-mer í’€ ë¡œë“œ ì™„ë£Œ.\")\n",
    "\n",
    "    # ì–‘ì„± ë° ìŒì„± í’€ ì„¤ì •\n",
    "    pool_pos = [pools_human, pools_paired_human]\n",
    "    pool_neg = [pools_paired_mouse]\n",
    "    \n",
    "    # --- ë°ì´í„°ì…‹ ë¡œë“œ ---\n",
    "    base_path = os.path.join(data_dir, 'abnativ', dataset_type)\n",
    "    \n",
    "    diverse_seqs = read_txt(os.path.join(base_path, TEST_DATASETS[dataset_type]['diverse']))\n",
    "    mouse_seqs = read_txt(os.path.join(base_path, TEST_DATASETS[dataset_type]['mouse']))\n",
    "    rhesus_seqs = read_txt(os.path.join(base_path, TEST_DATASETS[dataset_type]['rhesus']))\n",
    "    pssm_seqs = read_txt(os.path.join(base_path, TEST_DATASETS[dataset_type]['pssm']))\n",
    "    human_seqs = read_txt(os.path.join(base_path, TEST_DATASETS[dataset_type]['human']))\n",
    "    \n",
    "    # --- ì ìˆ˜ ê³„ì‚° ---\n",
    "    print(f\"\\n--- ë°ì´í„°ì…‹ '{dataset_type}' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\")\n",
    "\n",
    "    diverse_pred, diverse_true = calc_scores(diverse_seqs, pool_pos=pool_pos, pool_neg=pool_neg, label=1)\n",
    "    human_pred, human_true = calc_scores(human_seqs, pool_pos=pool_pos, pool_neg=pool_neg, label=1)\n",
    "    mouse_pred, mouse_true = calc_scores(mouse_seqs, pool_pos=pool_pos, pool_neg=pool_neg, label=0)\n",
    "    rhesus_pred, rhesus_true = calc_scores(rhesus_seqs, pool_pos=pool_pos, pool_neg=pool_neg, label=0)\n",
    "    pssm_pred, pssm_true = calc_scores(pssm_seqs, pool_pos=pool_pos, pool_neg=pool_neg, label=0)\n",
    "\n",
    "    # --- íƒœìŠ¤í¬ ì¡°í•© ---\n",
    "    tasks = {\n",
    "        'human_mouse': {'pred': human_pred + mouse_pred, 'true': human_true + mouse_true},\n",
    "        'human_pssm': {'pred': human_pred + pssm_pred, 'true': human_true + pssm_true},\n",
    "        'human_rhesus': {'pred': human_pred + rhesus_pred, 'true': human_true + rhesus_true},\n",
    "        'diverse_human_mouse': {'pred': diverse_pred + mouse_pred, 'true': diverse_true + mouse_true},\n",
    "        'diverse_human_pssm': {'pred': diverse_pred + pssm_pred, 'true': diverse_true + pssm_true},\n",
    "        'diverse_human_rhesus': {'pred': diverse_pred + rhesus_pred, 'true': diverse_true + rhesus_true},\n",
    "    }\n",
    "\n",
    "    # --- ê²°ê³¼ ì¶œë ¥ (ê·¸ë˜í”„ ìƒì„±) ---\n",
    "    print(\"\\n--- ë¶„ë¥˜ ì§€í‘œ ì‹œê°í™” ì‹œì‘ ---\")\n",
    "    for k, v in tasks.items():\n",
    "        task_name, pred, true = k, v['pred'], v['true']\n",
    "        \n",
    "        if true:\n",
    "            # ìˆ˜ì •ëœ classification í•¨ìˆ˜ í˜¸ì¶œ (ê·¸ë˜í”„ ìƒì„± ë° ì¸ë¼ì¸ ì¶œë ¥)\n",
    "            classification(pred, true, task_name=task_name, dataset_type=dataset_type)\n",
    "        else:\n",
    "            print(f\"âš ï¸ íƒœìŠ¤í¬ '{task_name}': ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ABNATIV_DATASET_TYPE = 'vkappa'  # vh, vkappa, vlambda ì¤‘ ì„ íƒ ê°€ëŠ¥\n",
    "\n",
    "\n",
    "    try:\n",
    "        run_benchmark(ABNATIV_DATASET_TYPE, data_dir=DATA_DIR)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nğŸ”¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        print(\"K-mer í’€ íŒŒì¼ì´ 'data' ë””ë ‰í„°ë¦¬ ë‚´ì— ì˜¬ë°”ë¥´ê²Œ ìœ„ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immunoseq (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
